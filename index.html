<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Transcription</title>
    <style>
        @font-face {
            font-family: 'Geist';
            src: url('/static/fonts/GeistVF.woff2') format('woff2');
            font-weight: 100 900;
            font-display: swap;
        }

        @font-face {
            font-family: 'Geist Mono';
            src: url('/static/fonts/GeistMonoVF.woff2') format('woff2');
            font-weight: 100 900;
            font-display: swap;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Geist', system-ui, -apple-system, sans-serif;
            background: #ffffff;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 40px 20px;
            color: #000000;
        }

        .app-container {
            max-width: 700px;
            width: 100%;
            display: flex;
            flex-direction: column;
            gap: 0;
        }

        .main-card {
            width: 100%;
            background: #ffffff;
            border: 1px solid #000000;
            border-radius: 20px;
            padding: 60px 50px;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 30px;
        }

        .orb-container {
            position: relative;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 10px;
        }

        .info-row {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 8px;
            margin-bottom: 10px;
        }

        .orb {
            width: 250px;
            height: 250px;
            border-radius: 50%;
            background: #ffffff;
            border: 2px solid #000000;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            transition: all 0.2s ease;
            position: relative;
            overflow: hidden;
        }

        .orb[data-state="inactive"] {
            background: #f5f5f5;
            border: 2px solid #000000;
        }

        .orb[data-state="active"] {
            background: #000000;
            border: 2px solid #000000;
        }

        .orb[data-state="muted"] {
            background: #ffffff;
            border: 2px solid #cccccc;
        }

        .waveform-container {
            position: absolute;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            gap: 5px;
        }

        .orb[data-state="active"] .waveform-container {
            justify-content: flex-start;
            padding-top: 20px;
        }

        .waveform-bars {
            display: none;
            align-items: center;
            justify-content: center;
            gap: 4px;
            height: 300px;
        }

        .orb[data-state="active"] .waveform-bars {
            display: flex;
        }

        .waveform-bar {
            width: 6px;
            background: #ffffff;
            border-radius: 3px;
            transition: height 0.1s ease;
        }

        .mic-icon {
            width: 74px;
            height: 74px;
            position: relative;
            z-index: 10;
            stroke: #666666;
        }

        .orb[data-state="active"] .mic-icon {
            width: 75px;
            height: 75px;
            stroke: #ffffff;
            transform: translateY(-45px);
        }

        .orb[data-state="muted"] .mic-icon {
            stroke: #cccccc;
            width: 74px;
            height: 74px;
        }

        .orb[data-state="muted"] .mic-strike {
            display: block !important;
        }

        .metadata {
            text-align: center;
            color: #000000;
            font-size: 14px;
            font-weight: 400;
            font-family: 'Geist Mono', 'SF Mono', monospace;
            letter-spacing: 0.02em;
        }

        .status-message {
            text-align: center;
            color: #666666;
            font-size: 14px;
            font-weight: 300;
            min-height: 20px;
        }

        .transcription-container {
            width: 100%;
            position: relative;
        }

        .transcription {
            background: #ffffff;
            border: 1px solid #000000;
            border-radius: 12px;
            padding: 30px;
            min-height: 300px;
            max-height: 500px;
            overflow-y: auto;
            width: 100%;
            font-size: 16px;
            line-height: 1.8;
            color: #000000;
            font-family: 'Geist', system-ui, sans-serif;
            font-weight: 300;
        }

        .transcription.empty {
            color: #999999;
            font-weight: 300;
            font-style: normal;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .copy-button {
            position: absolute;
            top: 15px;
            right: 15px;
            background: transparent;
            border: 1px solid #000000;
            border-radius: 6px;
            padding: 8px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.2s ease;
            color: #000000;
        }

        .copy-button:hover {
            background: #000000;
            color: #ffffff;
        }

        .copy-button:hover svg {
            stroke: #ffffff;
        }

        .copy-button svg {
            width: 20px;
            height: 20px;
        }

        .copy-button.copied {
            background: #000000;
            color: #ffffff;
        }

        .copy-button.copied svg {
            stroke: #ffffff;
        }

        .permission-prompt {
            background: #ffffff;
            border: 1px solid #000000;
            border-radius: 20px;
            padding: 60px 50px;
            text-align: center;
        }

        .permission-prompt h2 {
            color: #000000;
            margin-bottom: 15px;
            font-weight: 300;
            font-size: 24px;
        }

        .permission-prompt p {
            color: #666666;
            margin-bottom: 25px;
            font-weight: 300;
        }

        .permission-prompt button {
            background: #000000;
            color: #ffffff;
            border: 1px solid #000000;
            border-radius: 8px;
            padding: 15px 40px;
            font-size: 16px;
            font-weight: 400;
            cursor: pointer;
            transition: all 0.2s ease;
        }

        .permission-prompt button:hover {
            background: #ffffff;
            color: #000000;
        }

        .error-message {
            background: #ffffff;
            color: #000000;
            padding: 20px;
            border: 1px solid #000000;
            border-radius: 12px;
            text-align: center;
            margin-top: 20px;
            font-weight: 300;
        }

        @media (max-width: 600px) {
            .main-card {
                padding: 40px 30px;
            }

            .orb {
                width: 180px;
                height: 180px;
            }

            .transcription {
                padding: 20px;
                font-size: 16px;
            }

            .permission-prompt {
                padding: 40px 30px;
            }
        }
    </style>
</head>
<body>
    <div class="app-container" id="appContainer">
        <div id="mainApp" class="main-card">
            <div class="orb-container">
                <div class="orb" id="orb" data-state="inactive" tabindex="0" role="button" aria-label="Click to start recording">
                    <div class="waveform-container" id="waveformContainer">
                        <div class="waveform-bars">
                            <div class="waveform-bar"></div>
                            <div class="waveform-bar"></div>
                            <div class="waveform-bar"></div>
                            <div class="waveform-bar"></div>
                            <div class="waveform-bar"></div>
                            <div class="waveform-bar"></div>
                            <div class="waveform-bar"></div>
                            <div class="waveform-bar"></div>
                        </div>
                        <svg class="mic-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
                            <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
                            <line x1="12" y1="19" x2="12" y2="23"></line>
                            <line x1="8" y1="23" x2="16" y2="23"></line>
                            <line class="mic-strike" x1="3" y1="3" x2="21" y2="21" stroke-width="2.5" style="display: none;"></line>
                        </svg>
                    </div>
                </div>
            </div>

            <div class="info-row">
                <div class="metadata" id="metadata">Language: -- • 0.00s</div>
                <div class="status-message" id="statusMessage"></div>
            </div>

            <div class="transcription-container">
                <button class="copy-button" id="copyButton" aria-label="Copy transcription">
                    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                </button>
                <div class="transcription empty" id="transcription">
                    Speak to start transcribing...
                </div>
            </div>
        </div>

        <div id="errorMessage" class="error-message" style="display: none;"></div>
    </div>

    <script>
        let mediaRecorder;
        let isRecording = false;
        let isMuted = false;
        let chunkCounter = 0;
        let sessionId = null;
        let mediaStream = null;
        let audioContext = null;
        let analyser = null;
        let animationFrameId = null;
        let accumulatedChunks = [];
        let isInitialized = false;
        let noVoiceTimeout = null;

        const orb = document.getElementById('orb');
        const transcription = document.getElementById('transcription');
        const metadata = document.getElementById('metadata');
        const statusMessage = document.getElementById('statusMessage');
        const waveformBars = document.querySelectorAll('.waveform-bar');
        const errorMessage = document.getElementById('errorMessage');
        const copyButton = document.getElementById('copyButton');

        const VOICE_THRESHOLD = 10;
        const NO_VOICE_DELAY = 3000;

        async function requestMicrophonePermission() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                await initializeApp(stream);
                isInitialized = true;
            } catch (error) {
                console.error('Microphone permission denied:', error);
                showError('Microphone access denied. Please grant permission to use this app.');
            }
        }

        async function initializeApp(stream) {
            mediaStream = stream;
            sessionId = Date.now().toString();

            initializeWaveform(stream);
            startRecording();
            updateOrbState('active');
        }

        function initializeWaveform(stream) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            const microphone = audioContext.createMediaStreamSource(stream);

            microphone.connect(analyser);
            analyser.fftSize = 256;

            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);

            function updateWaveform() {
                if (!analyser) return;

                animationFrameId = requestAnimationFrame(updateWaveform);

                analyser.getByteFrequencyData(dataArray);

                const average = dataArray.reduce((a, b) => a + b) / bufferLength;

                waveformBars.forEach((bar, index) => {
                    const value = dataArray[index * 8] || 0;
                    const height = Math.max(40, (value / 255) * 300);
                    bar.style.height = `${height}px`;
                });

                if (!isMuted) {
                    if (average < VOICE_THRESHOLD) {
                        if (!noVoiceTimeout) {
                            noVoiceTimeout = setTimeout(() => {
                                if (!isMuted) {
                                    statusMessage.textContent = 'No voice detected';
                                }
                            }, NO_VOICE_DELAY);
                        }
                    } else {
                        if (noVoiceTimeout) {
                            clearTimeout(noVoiceTimeout);
                            noVoiceTimeout = null;
                        }
                        statusMessage.textContent = '';
                    }
                }
            }

            updateWaveform();
        }

        function startRecording() {
            if (!mediaStream) return;

            chunkCounter = 0;
            transcription.textContent = '';
            transcription.classList.remove('empty');
            isRecording = true;

            startNewRecordingSegment();
        }

        function startNewRecordingSegment() {
            if (!isRecording || isMuted) return;

            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }

            mediaRecorder = new MediaRecorder(mediaStream);
            accumulatedChunks = [];

            console.log('[MediaRecorder] Starting new recording segment');

            mediaRecorder.addEventListener('dataavailable', (event) => {
                console.log(`[MediaRecorder] dataavailable event fired: size=${event.data.size} bytes, state=${mediaRecorder.state}`);

                if (event.data.size > 0) {
                    accumulatedChunks.push(event.data);
                }
            });

            mediaRecorder.addEventListener('stop', async () => {
                console.log(`[MediaRecorder] stop event fired, accumulated ${accumulatedChunks.length} chunks`);

                if (accumulatedChunks.length > 0 && isRecording && !isMuted) {
                    const completeBlob = new Blob(accumulatedChunks, { type: 'audio/webm' });
                    console.log(`[MediaRecorder] Created complete blob: size=${completeBlob.size} bytes`);
                    await sendChunkForTranscription(completeBlob);

                    setTimeout(startNewRecordingSegment, 0);
                }
            });

            mediaRecorder.start();

            setTimeout(() => {
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    console.log('[MediaRecorder] Stopping after 3 seconds');
                    mediaRecorder.stop();
                }
            }, 3000);
        }

        async function sendChunkForTranscription(audioBlob) {
            const formData = new FormData();
            formData.append('audio', audioBlob, 'chunk.webm');
            formData.append('chunk_index', chunkCounter);
            formData.append('session_id', sessionId);

            const currentChunkIndex = chunkCounter;
            chunkCounter++;

            console.log(`[Chunk ${currentChunkIndex}] Sending chunk to server: size=${audioBlob.size} bytes`);

            try {
                console.log(`[Chunk ${currentChunkIndex}] Fetch started`);
                const response = await fetch('/transcribe-live', {
                    method: 'POST',
                    body: formData
                });

                console.log(`[Chunk ${currentChunkIndex}] Response received, starting to read stream`);

                const reader = response.body.getReader();
                const decoder = new TextDecoder();
                let buffer = '';

                while (true) {
                    const { done, value } = await reader.read();

                    if (done) {
                        console.log(`[Chunk ${currentChunkIndex}] Stream complete`);
                        break;
                    }

                    buffer += decoder.decode(value, { stream: true });
                    const lines = buffer.split('\n\n');
                    buffer = lines.pop();

                    for (const line of lines) {
                        if (line.startsWith('data: ')) {
                            const data = JSON.parse(line.slice(6));
                            console.log(`[Chunk ${currentChunkIndex}] Received event:`, data);

                            if (data.type === 'metadata') {
                                if (currentChunkIndex === 0) {
                                    updateMetadata(data.language, data.duration || 0);
                                }
                            } else if (data.type === 'segment') {
                                console.log(`[Chunk ${currentChunkIndex}] Appending text: "${data.text}"`);
                                appendTranscription(data.text);
                            } else if (data.type === 'error') {
                                console.error(`[Chunk ${currentChunkIndex}] Transcription error:`, data.message);
                            }
                        }
                    }
                }

            } catch (error) {
                console.error(`[Chunk ${currentChunkIndex}] Error sending chunk:`, error);
            }
        }

        function appendTranscription(text) {
            console.log(`[appendTranscription] Called with text: "${text}"`);
            console.log(`[appendTranscription] Current content: "${transcription.textContent}"`);
            console.log(`[appendTranscription] Has 'empty' class: ${transcription.classList.contains('empty')}`);

            if (transcription.classList.contains('empty')) {
                transcription.classList.remove('empty');
                transcription.textContent = '';
            }
            transcription.textContent += ' ' + text;

            console.log(`[appendTranscription] New content: "${transcription.textContent}"`);
            transcription.scrollTop = transcription.scrollHeight;
        }

        function updateMetadata(language, duration) {
            metadata.textContent = `Language: ${language} • ${duration.toFixed(2)}s`;
        }

        function updateOrbState(state) {
            orb.setAttribute('data-state', state);

            if (state === 'active') {
                orb.setAttribute('aria-label', 'Microphone active, click to mute');
            } else if (state === 'muted') {
                orb.setAttribute('aria-label', 'Microphone muted, click to unmute');
            }
        }

        async function toggleMute() {
            if (!isInitialized) {
                await requestMicrophonePermission();
                return;
            }

            isMuted = !isMuted;

            if (isMuted) {
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    mediaRecorder.stop();
                }
                isRecording = false;
                updateOrbState('muted');
                statusMessage.textContent = 'You are muted';
                statusMessage.style.color = '#999';
            } else {
                isRecording = true;
                startNewRecordingSegment();
                updateOrbState('active');
                statusMessage.textContent = '';
                statusMessage.style.color = '#666';
            }
        }

        function showError(message) {
            errorMessage.textContent = message;
            errorMessage.style.display = 'block';
        }

        async function copyTranscription() {
            const text = transcription.textContent;
            if (!text || transcription.classList.contains('empty')) {
                return;
            }

            try {
                await navigator.clipboard.writeText(text);
                copyButton.classList.add('copied');
                setTimeout(() => {
                    copyButton.classList.remove('copied');
                }, 2000);
            } catch (error) {
                console.error('Failed to copy text:', error);
            }
        }

        orb.addEventListener('click', toggleMute);

        orb.addEventListener('keydown', (e) => {
            if (e.key === ' ' || e.key === 'Enter') {
                e.preventDefault();
                toggleMute();
            }
        });

        copyButton.addEventListener('click', copyTranscription);

        window.addEventListener('beforeunload', () => {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
            }
            if (audioContext) {
                audioContext.close();
            }
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
            }
        });
    </script>
</body>
</html>
